[["index.html", "A Concise Introduction to Survey Sampling Preface", " A Concise Introduction to Survey Sampling Trang Bui 2026-01-18 Preface Survey sampling is one of the fundamental subjects in statistics. Survey statisticians have early dealt with problems such as nonresponse, unrepresentative samples, selection bias, etc. such that the tools they developed for these problems have inspired many methods in missing data, causal inference, and even machine learning. This book aims provide a concise, easy-to-understand introduction to basic sampling principles and techniques and their corresponding inference methods. Although the book can be quite simple without advanced topics such as nonresponse, small area estimation, and selection bias correction, I hope it will still inspire you to appreciate the development of survey sampling theories and go further to incorporate survey sampling techniques into your research. Disclaimer: This book uses definitions and roughly follows the structure of Lohr (2021). Some sections of this book also share similar narratives with another book of mine. "],["chap-intro.html", "1 Overview 1.1 Survey Sampling 1.2 Census vs. Samples 1.3 Variability and Bias 1.4 Sources of Bias", " 1 Overview 1.1 Survey Sampling To evolve and adapt, human make observations and identify patterns, from animal behaviors to hunt in our early days, to physical laws of the universe in the modern world. In these processes, we collect data from instances and try to generalize them into principles or conclusions that can be applied in other cases. Statistics is the branch of mathematics that studies such a process, namely data collection, analysis, and interpretation. Survey sampling is one of the fundamental subjects in statistics. In survey sampling, we are often interested in learning about a parameter of a target population. To understand what this means, we introduce some definitions: Observation unit: An object on which a measurement is taken. Variable of interest: The types of measurement taken on observation units that we want to study. Target population: The complete collection of observation units we want to study. This is also the collection of units that we want to make conclusions about. Parameter: A quantity that can be calculated from the variable of interest of the target population. Example 1.1 To better understand the above terminologies, let us consider an example where we are interested in how much students pay for rent. We will use this example throughout the book to illustrate different concepts in survey sampling. In this example, the variable of interest is the monthly rent expense. The observation units are students because we will “measure” their rent expenses. If we want to study the rent expense of all students in Canada, then our target population is all students who enroll in a Canadian university. A less ambitious target population is the student body of University of Saskatchewan. The parameter of our interest can be the average rent expense or the total dollar amount of rent paid by all students in the target population. Example 1.2 Another example is when an agricultural researcher want to estimate the yield of a crop. To do this, the researcher may want to grow that crop on multiple plots of land. The observation units are plots of land because we will “measure” the yield of a crop on those plots. Because the crop may have different yields at different environmental conditions, the possible target populations can be defined by locations. The researcher may want to get an estimate of the yield in the city of Saskatoon, or they want to get an estimate of the yield in the province of Saskatchewan, or a more ambitious goal will be the whole Canada. The parameter of our interest can be the average crop yield per acre. In survey sampling, we often assume that the population is finite1, and consists of \\(N &lt; \\infty\\) observation units. The population size \\(N\\) is also assumed to be fixed, although this assumption rarely holds in reality. Example 1.3 In 1.1, the USask student body may change every semester as current students graduate and new students enroll. 1.2 Census vs. Samples 1.2.1 Census To understand about the parameter of interest, we may try to collect data about every single observation unit in the target population. This is called a census. With a census, you can calculate the parameter of interest directly. A census also provides information on every subpopulation, no matter how small. Example 1.4 If we know the rent expense of every single student at USask, we will be able to calculate their average monthly rent expense directly. We will also be able calculate the average rent expense of every groups of students, for example, we will know the average students’ rent in every department. Notes: Many countries have censuses of birth and death records. In particular, Canada collect census data about its population every five years, often by sending invitation letters to all dwellings in Canada. Check out more information about Canadian censuses here. 1.2.2 Samples In many cases, due to constraints in cost, time, and other reasons, a census may not be possible. In this case, we may collect sample data. Sample: A subset of a population. Sampled population: The collection of all possible observation units that might have been chosen in a sample. This is the population from which the sample was taken. In practice, the sampled population rarely coincide with the target population (see Figure 1.1). Sampling unit: The unit that can be selected for a sample. Sometimes we want to study individuals but do not have a list of all individuals in the target distributions. In this case, the sampling unit may differ from the observation unit. Sampling frame: A list, map, or other specification of sampling units in the population from which a sample may be selected. Figure 1.1: Population and sample, from Figure 1.1. of Lohr (2021). Statistic: A quantity that can be calculated from the sample. We can use statistics to estimate or make conclusions about the population parameter. This process is called inference. In the next few chapters, we will consider (i) different sampling methods, then learn about (ii) how to make inferences in each of those sampling cases. Example 1.5 In the students’ rent example, we may decide to go to several randomly chosen classes on campus to interview students about their rent expenses. Here, the sampling frame is the list of all USask classes held this semester, and the sampling units are USask classes, instead of individual students. The sampled population are students who attend classes on the day we conduct our interviews. This excludes remote students, or thesis-writing students, for example. The sample is the actual students who were interviewed by us. The statistic can be the average rent payments made by these specific students. Since samples are much smaller than censuses, data collection for samples are often conducted with more care. Thus, if samples are collected in an appropriate manner, inferences from samples can be more reliable than censuses. 1.3 Variability and Bias A sampling protocol is a plan to collect sample data. Before learning different sampling method to devise a sampling protocol, we introduce the the concepts of variability and bias to identify what makes a good sampling protocol. 1.3.1 Variability In most cases, the list of observation units included in a sample is random, intentionally or not. The sample-to-sample difference (under the same sampling protocol) is called the variability of the sampling protocol. A sampling protocol with low variability is a sampling protocol with high precision. Example 1.6 Suppose I randomly choose one region in Saskatoon and then ask students in that region about their rent. In this case, my sampling protocol will have a high variability or a low precision. This is because if I repeat this same sample collecting method for many times, every time I will interview students living in a different region. Since rent will depend on specific regions and their distances to school, the rent data I collect will tend to be substantially different from one sample to another. 1.3.2 Bias The difference between the population data and the average of different samples (coming from the same sampling protocol) is called the bias of the sampling protocol. Small bias means high accuracy. Bias is often caused by systematic differences between the target population and sample. Example 1.7 Suppose I only interview female students. Even if I repeat this same sample collection method many times, I will only get the data that tells me about the rent expense for female students. This data will likely be different from the rent expense for all students. Hence I say the bias is high and accuracy is low. Figure 1.2 summarizes concepts about bias, variance, accuracy and precision. Figure 1.2: Accuracy and precision. Because we want to get an accurate and precise estimation of the population parameter, good sampling protocol should have low variance and low bias. You will learn from this course that we are usually able to reduce the variability by choosing an appropriate sampling method. On the other hand, bias is a much harder and more subtle problem to deal with. In practice, it can be even impossible to avoid bias. 1.4 Sources of Bias 1.4.1 Selection Bias Selection bias occurs when the target population does not coincide with the sampled population, or when some population units are sampled at a different rate than intended by the investigator. Some ways in which selection bias can occur are: convenience samples: when researchers conduct surveys on the first subset of population units they encounter; judgement samples: when researchers deliberately and intentionally select a “representative” sample; self-selected samples: when the sample only consists of volunteer; undercoverage: when the sampling frame fails to include some members of the target population; overcoverage: when units not in the target population can end up in the sample; nonresponse: when responses from some members of the chosen samples are not collected. Example 1.8 If we choose to interview our friends on their rent, because they are easier to interview, we are collecting a convenience sample. If we look at people walking on the street and use our judgement to determine who we think are spending the average rent and go to interview them, we are collecting a judgement sample. If we hang on posters around school to let students to come to us by themselves, we are collecting a self-selected sample. In all these cases, there can be systematic differences between students in our sample compared to students in the population. Our friends may have a similar spending patterns as us while other students may have different opinions. Our judgement can easily be misleading regarding who we think are paying the average rent. Finally, volunteers are usually more motivated by rewards and may have a different spending behavior compared to the rest of the students. When we interview students by visiting classes, we may miss people who do not come to class, remote students, graduate students who are writing their theses, medical residents, and so on. This induces undercoverage. When we send out emails with rewards for students to participate in our surveys, we may also end up collecting data from people who are not eligible but are motivated by the rewards and make up their eligibility. This leads us to the overcoverage problem. Even when we actually get to interview a student, they may choose not to disclose their information. These students can be more private and have a different rent selection than the one who reply to our interviews. Here, we run into a nonresponse problem. 1.4.2 Measurement Errors Measurement errors occur when the survey response has a tendency to differ from the true value, especially when the tendency is in one direction. This can be due to inaccuracy of measurement tools or devices unreliable respondents: people sometimes do not tell the truth people forget people do not always understand the questions etc. Example 1.9 In the crop yield case of Example 1.2, plants on adjacent plots can be counted twice, inducing measurement errors. Therefore, when conducting surveys, we should pay attention to our sampling protocol so that we get responses or measurements as accurate as possible. For surveys that require a measurement tool or device, such an equipment needs to get a thorough reliability check. When designing questionnaires to survey individuals, we should pay attention to details that may influence respondents’ responses, such as the order and wording of the questions, the list of options provided, the attitude of the interviewers, etc. For a quick guide on questionnaire design, check this tutorial. This is called the finite population assumption↩︎ "],["chap-srs.html", "2 Simple Probability Sampling 2.1 Mathematical Framework 2.2 Sampling Distribution 2.3 Unbiased Estimator 2.4 Probability Sampling", " 2 Simple Probability Sampling 2.1 Mathematical Framework 2.1.1 Simplifying Assumptions Mathematics is ideal and beautiful and the world is messy. However, to study the world better, we must start with ideal, most simple cases, then build our theories upon that. From now on, we will assume that the sampled population is the same as the target population, and the sampling frame is complete. This implies that we assume that there is no nonresponse or missing data, no measurement error and no selection bias. 2.1.2 Population and Sample We represent the population by the sampling frame \\(U = \\{1, 2, ..., N\\}\\), where each index represents an observation unit. Then \\(U\\) is called the population index set. The letter \\(U\\) is used because the population can also be thought of as the universe that we are working on. As discussed in Section 1.2.2, a sample is a subset of the population. The sample is denoted by \\(S\\), where \\(S\\) stands for sample. Then \\(S \\subseteq U\\). Example 2.1 Suppose our population has 3 observation units. Then \\(U = \\{1, 2, 3\\}\\). The index \\(1\\) represents the first unit, the index \\(2\\) represents the second unit, and the index \\(3\\) represents the third unit. A sample \\(S\\) can be any subset of \\(U\\), so \\(S\\) can be \\(\\{1\\}, \\{1, 2\\}, \\{1, 2, 3\\}\\), or \\(\\{\\emptyset\\}\\), etc. 2.1.3 Variables A variable is a characteristic or quantity of the observation unit which can take different values. In the students’ rent Example 1.1, variables can be the monthly rent payment, age, department, etc. of students. General variables are often denoted by uppercase letters, for example, \\(X, Y, Z\\). Variables of a specific unit, say unit \\(i\\), is denoted by the uppercase letter accompanied by a subscript, e.g., \\(X_i, Y_i, Z_i\\). Actual values are denoted by lowercase letters \\(x_i, y_i, z_i\\). In survey sampling, there are often three types of variables: the variable of interest is often denoted by \\(Y\\). So in the population, we have \\(Y_1, Y_2, ..., Y_N\\) denote the variable of interest measured on each unit. explanatory (or auxiliary) variables: some additional variables that can be helpful, but are not the variable of interest. They are often denoted by \\(X\\) (\\(X\\) can be a vector of different variables). Thus, in the population we have \\(X_1, ..., X_N\\). inclusion variable, often denoted by \\(Z\\), in which \\(Z_i\\) indicates whether unit \\(i\\) is included in the sample, that is \\[ Z_i = \\begin{cases} 1 &amp; \\text{if } i \\in S \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\] The set \\(\\{Z_1, ..., Z_N\\}\\) uniquely determines the set \\(S\\). Or equivalently, we can say that there is a 1-1 correspondence between \\(\\{Z_1, ..., Z_N\\}\\) and \\(S\\). Example 2.2 In the students’ rent Example 1.1, the monthly rent payment is the variable of interest, so it is denoted by \\(Y\\). Then, \\(Y_1, Y_2, ..., Y_N\\) denote the monthly rent payment of the first, the second, …, the last student in the population, respectively. If the \\(i\\)-th student pays \\(\\$1,000\\) monthly for rent, then \\(y_i = 1,000\\). We use \\(y_i\\) to represent an actual number, but it can be any number. The explanatory variables can be a collection of information such as department, age, height, weight, etc. and are represented by \\(X\\). Finally, \\(Z_i\\) denotes whether the \\(i\\)-th student is included in our sample. Example 2.3 For each possible sample \\(S\\) from the population \\(U\\), we have a specific set of values for \\(\\{Z_1, ..., Z_N\\}\\). Continue from Example 2.1, if \\(U = \\{1, 2, 3\\}\\) then \\(S\\) and \\(Z_1, ..., Z_N\\) can take values: \\(S\\) \\(Z_1\\) \\(Z_2\\) \\(Z_3\\) \\(\\{\\emptyset\\}\\) \\(0\\) \\(0\\) \\(0\\) \\(\\{1\\}\\) \\(1\\) \\(0\\) \\(0\\) \\(\\{2\\}\\) \\(0\\) \\(1\\) \\(0\\) \\(\\{3\\}\\) \\(0\\) \\(0\\) \\(1\\) \\(\\{1,2\\}\\) \\(1\\) \\(1\\) \\(0\\) \\(\\{1,3\\}\\) \\(1\\) \\(0\\) \\(1\\) \\(\\{2,3\\}\\) \\(0\\) \\(1\\) \\(1\\) \\(\\{1,2,3\\}\\) \\(1\\) \\(1\\) \\(1\\) 2.1.4 Population Parameter and Sample Statistic Recall from Chapter 1, the parameter is a quantity that can be calculated from the population, and the statistic is a quantity that can be calculated from the sample. The goal of survey sampling is to estimate a population parameter using a sample statistic. For a collection of numbers \\(x_1, ..., x_m\\), common descriptive statistics that we can calculate are the mean and the variance, which is defined respectively as \\[ \\bar{x} = \\frac{1}{m}(x_1 + x_2 + ... + x_m) = \\frac{1}{m}\\sum_{i=1}^m x_i \\] \\[ s^2 = \\frac{1}{m-1}\\sum_{i=1}^m (x_i - \\bar{x})^2 \\] Example 2.4 Consider 3 numbers \\(4,10,7\\). Then the mean is \\[ \\bar{x} = \\frac{1}{3}(4+10+7) = 7 \\] The variance is \\[ s^2 = \\frac{1}{3-1} \\left[(4-7)^2 + (10-7)^2 + (7-7)^2\\right] = 9 \\] The standard deviation is \\(s = \\sqrt{s^2} = 3\\). Similarly, we can use these definitions to define our population parameters and sample statistics. Population parameters are functions of the variables of interest \\(Y_1, ..., Y_N\\). Often, we are interested in the population mean: \\[ \\bar{Y}_U = \\frac{1}{N}\\sum_{i=1}^N Y_i \\] When \\(Y_i\\) is an indicator i.e., a binary variable, then \\(\\bar{Y}_U\\) can the called the population proportion. For example, if \\(Y_i\\) indicates whether the \\(i\\)-th student has a private bathroom with \\(Y_i = 1\\) meaning the student has a private bathroom and \\(Y_i = 0\\) meaning the student does not have a private bathroom, then \\(\\bar{Y}_U\\) indicates the proportion of USask students who have a private bathroom. Or the population total \\[ T_U = \\sum_{i=1}^N Y_i = N\\bar{Y}_U \\] Sample statistics can be calculated from a sample, therefore, they are functions of \\(Z_iY_i\\), and possibly \\(Z_iX_i\\) for \\(i = 1, ..., N\\). Note here that we use \\(Z_iY_i\\) because, when unit \\(i\\) is included in our sample, \\(Z_i = 1\\) and \\(Z_iY_i = Y_i\\) so \\(Y_i\\) is incorporated in our sample statistic. On the other hand, if \\(Z_i = 0\\), unit \\(i\\) is not included in our sample, then \\(Z_iY_i = 0\\) contributes 0 to our sample statistic. Corresponding to the population parameters, we also have the sample mean. Suppose the sample we collected consists of \\(n\\) unit: \\[ \\bar{Y}_S = \\frac{1}{n}\\sum_{i\\in S}Y_i = \\frac{1}{n}\\sum_{i=1}^N Z_iY_i = \\frac{\\sum_{i=1}^N Z_iY_i}{\\sum_{i=1}^N Z_i} \\] We also have the sample total: \\[ T_S = \\sum_{i\\in S}Y_i = \\sum_{i=1}^N Z_iY_i \\] 2.1.5 Design-based Inference In survey sampling, we usually use a mathematical framework called design-based, which consists of the following assumptions The population size (the number of units in the population) \\(N\\) is fixed and finite. For each \\(i = 1, 2,..., N\\), \\(Y_i, X_i\\) is fixed, but possibly unknown to us. Therefore, \\(Y_i, X_i\\) can be replaced by lowercase letters \\(y_i, x_i\\). The sample \\(S\\) is random. Therefore \\(Z_1, ..., Z_N\\) are random. To differentiate with fixed quantities, we denote random quantities with uppercase letters. So \\(Z\\) is the only source of randomness in this framework. Since \\(Z\\) determines which unit is selected, the specification of \\(Z\\) is called the design of the sampling process. Thus, this framework is called the design-based framework2. The design-based framework is gaining its popularity back in fields beyond survey sampling, such as causal inference or economics. To understand the difference between fixed and random, we introduce the notion of a probabilistic experiment. A probabilistic experiment is a process in which the complexity of the underlying system leads to an outcome that cannot be known ahead of time. We say that the outcome of such a probabilistic experiment is random. Thus, the outcomes can be different each time the probabilistic experiment is repeated. In the design-based framework, we assume that there is only one probabilistic experiment, which is the sample selection process. That is, we do not know which unit will end up in our sample ahead of time, and if we repeat the sample selection process, we will probably get a different actual list \\(s\\) of units in our sample. Since \\(Z\\) is related to \\(S\\), \\(Z\\) is assumed to be random. Since \\(Y\\) and \\(X\\) is not related to the probabilistic experiment, they are assumed to be fixed. \\(Y\\) and \\(X\\) can be thought of as being inherent for our sampling units (think about the height and weight of a student). However, they are unknown to us because we did not collect our survey data about all units in the population. 2.2 Sampling Distribution 2.2.1 Probability Refresh Although there are different views of what a probability means, in this course, we will use the empirical (or frequentist) view, in which the probability of an outcome of a probabilistic experiment is the frequency that we obtain such an outcome, if we are to repeat the probabilistic experiment for an infinitely large number of times. In our case, the probabilistic experiment is the sample selection process, the outcome is the sample index set \\(S\\). So the probability that we obtain a specific value \\(s\\) of \\(S\\) is \\[ \\mathbb{P}(S = s) = \\lim_{\\text{number of repetitions} \\to \\infty} \\frac{\\text{number times outcome } s \\text{ is obtained}}{\\text{number of repetitions}} \\] A random variable \\(Z\\) is a function of the experimental outcome. The probability that the random variable \\(Z\\) attain a specific value \\(z\\) is the sum of probabilities of possible experimental outcomes \\(s\\) in which \\(Z = z\\), that is: \\[ \\mathbb{P}(Z = z) = \\sum_{s \\text{ so that when }S=s, \\text{ then }Z=z}\\mathbb{P}(S=s) \\] Check out this letcure to learn more about probability and its laws. Example 2.5 Continue with Example 2.3, suppose we repeat the sample selection process for a large amount of times, obtaining results \\[ \\{1\\}, \\{2,3\\}, \\{1,2\\}, \\{2,3\\}, \\{1,2\\}, \\{2\\}, \\{2\\}, \\{1,2\\}, \\{1\\}, ... \\] We then calculate the frequency of the possible outcomes obtained, then obtain the probability for each possible outcomes of \\(S\\), namely \\(\\{\\emptyset\\}, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{1,2,3\\}\\) as follows: \\(S\\) \\(Z_1\\) \\(Z_2\\) \\(Z_3\\) \\(\\mathbb{P}(S=s)\\) \\(\\{\\emptyset\\}\\) \\(0\\) \\(0\\) \\(0\\) \\(0\\) \\(\\{1\\}\\) \\(1\\) \\(0\\) \\(0\\) \\(1/6\\) \\(\\{2\\}\\) \\(0\\) \\(1\\) \\(0\\) \\(1/3\\) \\(\\{3\\}\\) \\(0\\) \\(0\\) \\(1\\) \\(0\\) \\(\\{1,2\\}\\) \\(1\\) \\(1\\) \\(0\\) \\(1/3\\) \\(\\{1,3\\}\\) \\(1\\) \\(0\\) \\(1\\) \\(0\\) \\(\\{2,3\\}\\) \\(0\\) \\(1\\) \\(1\\) \\(1/6\\) \\(\\{1,2,3\\}\\) \\(1\\) \\(1\\) \\(1\\) \\(0\\) From here, we can calculate \\(\\mathbb{P}(Z_1 = 1)\\), i.e., the probability that unit 1 is in our sample, by summing up the probabilities of sample index sets that contain 1: \\[\\begin{align*} \\mathbb{P}(Z_1 = 1) &amp; = \\mathbb{P}(S = \\{1\\}) + \\mathbb{P}(S = \\{1,2\\}) + \\mathbb{P}(S = \\{1,3\\}) + \\mathbb{P}(\\{1,2,3\\}) \\\\ &amp; = 1/6 + 1/3 + 0 + 0 = 1/2 \\end{align*}\\] Similarly, the probability that unit 1 is not in our sample can be calculated by summing up the probabilities of possible sample index sets that do not contain 1: \\[\\begin{align*} \\mathbb{P}(Z_1 = 0) &amp; = \\mathbb{P}(S = \\{2\\}) + \\mathbb{P}(S = \\{3\\}) + \\mathbb{P}(S = \\{2,3\\}) + \\mathbb{P}(\\{\\emptyset\\}) \\\\ &amp; = 1/3 + 0 + 1/6 + 0 = 1/2 \\end{align*}\\] Since \\(Z_1\\) is a binary variable that can only takes 2 possible values: 1 or 0, so we can also use the probability law of complement to calculate \\(\\mathbb{P}(Z_1 = 0)\\): \\[ \\mathbb{P}(Z_1 = 0) = 1 - \\mathbb{P}(Z_1 = 1) = 1 - 1/2 = 1/2. \\] 2.2.2 Sampling Distribution Recall that in survey sampling, we try to use a sample statistic to estimate a population parameter, say \\(\\theta\\). In Section 2.1.4, we discussed that \\(\\theta\\) is a function of \\(Y_i\\), \\(i=1,...,N\\) and it can be, for example, the population sample or the population mean. Under the design-based framework discussed in Section 2.1.5, \\(Y_i\\) is assumed to be fixed, and \\(\\theta\\) is a function of \\(Y_i\\). As a consequence, \\(\\theta\\) is also assumed to be fixed. Thus, we can use lowercase letters to denote \\(\\theta\\). For example, the population total: \\[\\begin{equation} t_U = \\sum_{i=1}^N y_i \\tag{2.1} \\end{equation}\\] The population mean is \\[\\begin{equation} \\bar{y}_S = \\frac{1}{N}t_U = \\frac{1}{N}\\sum_{i=1}^N y_i \\tag{2.2} \\end{equation}\\] An estimator of \\(\\theta\\) is usually denoted with a hat: \\(\\hat{\\theta}\\). In Section 2.1.4, \\(\\hat{\\theta}\\) is a statistic calculated from the sample, so it is a function of \\(Z_iY_i\\) and possibly \\(Z_iX_i\\). In the design-based framework of Section 2.1.5, \\(Z_i\\) is assumed to be random, so \\(\\hat{\\theta}\\) is also random. Recall that we use lowercase letters to denote fixed and uppercase letters to denote random. So we write the sample total* as \\[\\begin{equation} T_S = \\sum_{i \\in S} y_i = \\sum_{i=1}^N Z_iy_i \\tag{2.3} \\end{equation}\\] and write the sample mean** as (if we have \\(n\\) units in our sample) \\[\\begin{equation} \\bar{Y}_S = \\frac{1}{n}\\sum_{i\\in S}y_i = \\frac{1}{n}\\sum_{i=1}^N Z_iy_i = \\frac{\\sum_{i=1}^N Z_iy_i}{\\sum_{i=1}^N Z_i} \\tag{2.4} \\end{equation}\\] We can see that the sample mean is a division of two random quantities, so it is more difficult than the sample total. So we will study the sample total and population total first. Again, \\(\\hat{\\theta}\\) is random due to the randomness from the sample selection probabilistic experiment. This implies that each time the probabilistic experiment is repeated, we will probably get a different value of \\(\\hat{\\theta}\\). The distribution formed by the frequency of possible values of \\(\\hat{\\theta}\\) when we repeat the sample selection processes infinitely many times is called the sampling distribution of \\(\\hat{\\theta}\\). The sampling distribution tells us about the probabilities that certain values/range of values of \\(\\hat{\\theta}\\) is obtained. Example 2.6 Continue with Example 2.5. Suppose that \\(Y_1 = 4\\), \\(Y_2 = 10\\), \\(Y_3 = 7\\). The population total is \\[ t_U = \\sum_{i=1}^3 Y_i = Y_1 + Y_2 + Y_3 = 4 + 10 + 7 = 21. \\] Consider the sample total \\(T_S = \\sum_{i=1}^N Z_i Y_i\\): \\(S\\) \\(Z_1\\) \\(Z_2\\) \\(Z_3\\) \\(\\mathbb{P}(S=s)\\) \\(T_S\\) \\(\\{\\emptyset\\}\\) \\(0\\) \\(0\\) \\(0\\) \\(0\\) \\(0\\) \\(\\{1\\}\\) \\(1\\) \\(0\\) \\(0\\) \\(1/6\\) \\(4\\) \\(\\{2\\}\\) \\(0\\) \\(1\\) \\(0\\) \\(1/3\\) \\(10\\) \\(\\{3\\}\\) \\(0\\) \\(0\\) \\(1\\) \\(0\\) \\(7\\) \\(\\{1,2\\}\\) \\(1\\) \\(1\\) \\(0\\) \\(1/3\\) \\(14\\) \\(\\{1,3\\}\\) \\(1\\) \\(0\\) \\(1\\) \\(0\\) \\(11\\) \\(\\{2,3\\}\\) \\(0\\) \\(1\\) \\(1\\) \\(1/6\\) \\(17\\) \\(\\{1,2,3\\}\\) \\(1\\) \\(1\\) \\(1\\) \\(0\\) \\(21\\) We can see that, depending on the actual sample we obtain from our sample selection process, \\(T_S\\) can have different values. Since the result of the sample selection process cannot be known beforehand and is random, the actual value of \\(T_S\\) as a result of the sample selection process, is also random. To visualize the sampling distribution of \\(T_S\\), we can draw a plot of the probabilities of different actual values of \\(T_S\\): plot(x = c(0, 4, 10, 7, 14, 11, 17, 21), y = c(0, 1/6, 1/3, 0, 1/3, 0, 1/6, 0), ylab = &quot;probability&quot;, xlab = &quot;possible values of T_S&quot;, main = &quot;Sampling distribution of T_S&quot;, type = &quot;h&quot;, lwd = 10) From the plot, we can see that \\[ \\mathbb{P}(T_S = 4) = 1/6; \\hspace{5mm} \\mathbb{P}(T_S = 10) = 1/3; \\hspace{5mm} \\mathbb{P}(T_S = 14) = 1/3; \\hspace{5mm} \\mathbb{P}(T_S = 17) = 1/6. \\] and the probability that \\(T_S\\) has other values outside of \\(4, 10, 14, 17\\) is 0. 2.2.3 Probabilistic Mean The (probabilistic) mean of a numerical-valued random variable is defined as \\[ \\mathbb{E}[Z] = \\sum_{\\text{possible values }z \\text{ of }Z} z \\times \\mathbb{P}(Z = z) \\] Example 2.7 Continue with Example 2.6, the mean of random variable \\(Z_1\\) is \\[ \\mathbb{E}[Z_1] = 1 \\times \\mathbb{P}(Z_1 = 1) + 0 \\times \\mathbb{P}(Z_1 = 0) = 1 \\times 1/2 + 0 \\times 1/2 = 1/2. \\] Note here that for a binary random variable \\(Z\\) having only two possible outcomes \\(1\\) or \\(0\\), we always have \\[\\begin{equation} \\mathbb{E}[Z] = 1 \\times \\mathbb{P}(Z = 1) + 0 \\times \\mathbb{P}(Z = 0) = \\mathbb{P}(Z = 1). \\tag{2.5} \\end{equation}\\] Example 2.8 Continue with Example 2.6, we have \\[\\begin{align*} \\mathbb{E}[Z_2] = \\mathbb{P}(Z_2 = 1) &amp; = \\mathbb{P}(S = \\{2\\}) + \\mathbb{P}(S = \\{1,2\\}) + \\mathbb{P}(S = \\{2,3\\}) + \\mathbb{P}(S = \\{1,2,3\\}) \\\\ &amp; = 1/3 + 1/3 + 1/6 + 0 = 5/6. \\end{align*}\\] and \\[ \\mathbb{E}[Z_3] = \\mathbb{P}(Z_3 = 1) = 0 + 0 + 1/6 + 0 = 1/6. \\] 2.3 Unbiased Estimator 2.3.1 Bias Since sample statistics are random, which means it can obtain different values at different repetition of the sampling selection, we need to use the concepts of bias and variance in Section 1.3 to evaluate estimators. We will first look at bias. Mathematically, bias is defined as \\[ \\text{Bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta \\] If \\(\\text{Bias}(\\hat{\\theta}) = 0\\), we say \\(\\hat{\\theta}\\) is unbiased for \\(\\theta\\). Otherwise, we say that \\(\\hat{\\theta}\\) is biased for \\(\\theta\\). Example 2.9 Continue with Example 2.6, the mean of the sample total \\(T_S\\) is \\[ \\mathbb{E}[T_S] = 4 \\times 1/6 + 10 \\times 1/3 + 14 \\times 1/3 + 17 \\times 1/6 = 11.5 \\] However, we want to estimate the population total, \\(t_U = 21\\). So the bias of \\(T_S\\) for \\(t_U\\) is \\[ \\mathbb{E}[T_S] - t_U = 11.5 - 21 = -9.5. \\] 2.3.2 Bias of Sample Total To calculate the bias formula of the sample total \\(T_S\\), we need to calculate its mean. In doing so, we use the following property: Proposition 2.1 (Linearity of Means) For random variables \\(Z_1\\), \\(Z_2\\), and constants (fixed numbers) \\(a\\) and \\(b\\), we have \\[ \\mathbb{E}[aZ_1 + bZ_2] = a\\mathbb{E}[Z_1] + b\\mathbb{E}[Z_2]. \\] In general, if we have \\(N\\) random variables \\(Z_1, ..., Z_N\\) and \\(N\\) constants \\(a_1, ..., a_N\\), we have \\[ \\mathbb{E}\\left[\\sum_{i=1}^N a_iZ_i\\right] = \\sum_{i=1}^N a_i\\mathbb{E}\\big[Z_i\\big]. \\] Basically, the linearity property of the means says that expectation (i.e., mean) of a linear combination of random variables equals the linear combination of the expectations (i.e., means) of the corresponding random variables. Applying Property 2.1 to the sample total, we have \\[ \\mathbb{E}\\big[T_S\\big] = \\mathbb{E}\\left[\\sum_{i=1}^N Z_iy_i\\right] = \\sum_{i=1}^N\\mathbb{E}\\big[Z_i\\big]y_i \\] where the first equation is from the definition in Equation (2.3), the second equation is from the linearity property of the mean and the design-based framework, which assumes that \\(y_i\\), \\(i=1, ..., N\\) are fixed (constants). So, the bias of the sample total \\(T_S\\) when estimating the population \\(t_U\\) is \\[ \\mathbb{E}\\big[T_S\\big] - t_U = \\sum_{i=1}^N\\mathbb{E}\\big[Z_i\\big]y_i - \\sum_{i=1}^Ny_i = \\sum_{i=1}^N\\Big\\{\\big(\\mathbb{E}[Z_i] - 1\\big)y_i\\Big\\} \\] which is often non-zero, meaning that \\(T_S\\) is often biased for \\(t_U\\). Furthermore, note that \\(Z_i\\), \\(i = 1, ..., N\\) are binary random variables which can only take one of two values, either 1 or 0, so from Equation (2.5), we have \\[ \\mathbb{E}\\big[Z_i\\big] = \\mathbb{P}(Z_i = 1) \\le 1 \\] Now, if \\(y_i \\ge 0\\) for all \\(i = 1, ..., N\\), for example, when \\(Y\\) is the monthly rent payment, then \\[ \\mathbb{E}\\big[T_S\\big] - t_U = \\sum_{i=1}^N\\Big\\{\\big(\\mathbb{E}[Z_i] - 1\\big)y_i\\Big\\} = \\sum_{i=1}^N\\Big\\{\\big[\\mathbb{P}(Z_i = 1) - 1\\big]y_i\\Big\\} \\le 0 \\] that is, \\(T_S\\) tends to underestimate \\(t_U\\) if \\(y_i \\ge 0\\) for all \\(i = 1, ..., N\\). This is what we have seen in Example 2.9. The only case where \\(T_S\\) is unbiased for \\(t_U\\) is when \\(\\Pr(Z_i = 1)\\) for all \\(i = 1, ..., N\\). This means that all units \\(i\\) in the population are included in our sample with certainty, implying that we are taking a census! 2.3.3 Horvitz-Thompson Estimator From the previous section, we notice that the sample total \\(T_S\\) is unbiased for the population total \\(t_U\\) only if we are taking a census. However, as discussed in Section 1.2.2, a census is usually impossible due to constraints in time, cost and other administrative issues. Thus, we cannot use the sample total to estimate the population total and we have to modify the sample total so that it become unbiased! For this, in 1952, the Horvitz-Thompson estimator is proposed: \\[\\begin{equation} \\hat{\\bar{T}}_{HT} = \\sum_{i \\in S}\\frac{y_i}{\\mathbb{P}(Z_i = 1)} = \\sum_{i=1}^N \\frac{Z_iy_i}{\\mathbb{P}(Z_i = 1)}. \\tag{2.6} \\end{equation}\\] Now, this estimator is unbiased: \\[ \\mathbb{E}\\big[\\hat{\\bar{T}}_{HT}\\big] = \\mathbb{E}\\left[\\sum_{i=1}^N \\frac{Z_iy_i}{\\mathbb{P}(Z_i = 1)}\\right] = \\sum_{i=1}^N\\mathbb{E}[Z_i] \\frac{y_i}{\\mathbb{P}(Z_i = 1)} = \\sum_{i=1}^N y_i = t_U \\] since \\(\\mathbb{E}[Z_i] = \\Pr(Z_i = 1)\\), \\(i = 1, ..., N\\) by Equation (2.5). The Horvitz-Thompson estimator is an important mathematical discovery and is the basis for many methods in not only survey sampling but also missing data, causal inference, domain adaptation, etc. Example 2.6 Continue with Example 2.5. Suppose that \\(Y_1 = 4\\), \\(Y_2 = 10\\), \\(Y_3 = 7\\). The population total is \\[ t_U = \\sum_{i=1}^3 Y_i = Y_1 + Y_2 + Y_3 = 4 + 10 + 7 = 21. \\] From Examples 2.7 and 2.8, we also know that \\[ \\mathbb{P}(Z_1 = 1) = 1/2; \\hspace{5mm} \\mathbb{P}(Z_2 = 1) = 5/6; \\hspace{5mm} \\mathbb{P}(Z_3 = 1) = 1/6 \\] so we can calculate \\(S\\) \\(Z_1\\) \\(Z_2\\) \\(Z_3\\) \\(\\mathbb{P}(S=s)\\) \\(T_S\\) \\(\\hat{\\bar{T}}_{HT}\\) \\(\\{\\emptyset\\}\\) \\(0\\) \\(0\\) \\(0\\) \\(0\\) \\(0\\) \\(0\\) \\(\\{1\\}\\) \\(1\\) \\(0\\) \\(0\\) \\(1/6\\) \\(4\\) \\(4/(1/2) = 8\\) \\(\\{2\\}\\) \\(0\\) \\(1\\) \\(0\\) \\(1/3\\) \\(10\\) \\(10/(5/6) = 12\\) \\(\\{3\\}\\) \\(0\\) \\(0\\) \\(1\\) \\(0\\) \\(7\\) \\(7/(1/6) = 42\\) \\(\\{1,2\\}\\) \\(1\\) \\(1\\) \\(0\\) \\(1/3\\) \\(14\\) \\(8+12= 20\\) \\(\\{1,3\\}\\) \\(1\\) \\(0\\) \\(1\\) \\(0\\) \\(11\\) \\(8+42=50\\) \\(\\{2,3\\}\\) \\(0\\) \\(1\\) \\(1\\) \\(1/6\\) \\(17\\) \\(12+42 = 54\\) \\(\\{1,2,3\\}\\) \\(1\\) \\(1\\) \\(1\\) \\(0\\) \\(21\\) \\(8+12+42 = 62\\) The mean of the Horvitz-Thompson estimator is \\[ \\mathbb{E}\\big[\\hat{\\bar{T}}_{HT}\\big] = 8 \\times \\frac{1}{6} + 12 \\times \\frac{1}{3} + 20 \\times \\frac{1}{3} + 54 \\times \\frac{1}{6} = 21 = t_U. \\] So we can see that although the Horvitz-Thompson estimator \\(\\hat{\\bar{T}}_{HT}\\) also results in different values at different sample index set, but on average, it is unbiased for \\(t_U\\). This is like throwing darts, although the dart may land at different places, but the locations of the landings still surround the bullseye. On the other hand, the sample total \\(T_S\\) is biased (except for special cases). This is similar to throwing darts but the locations of the landings do not surround the bullseye. Check Figure 2.1 for a visual illustration. Figure 2.1: Visual illustration of biases of different estimators 2.4 Probability Sampling There are other frameworks, such as the model-based framework, but it will not be the focus of this book.↩︎ "],["app-dataset.html", "A Data Set", " A Data Set We will use an artificially generated pseudo data set fakeRentPop.csv as a running example throughout the book. The data set contains information about an artificial population of students’ rent expenses. The variables collected in the data set corresponds to columns in the data set, namely rent: monthly rent expense of the student, which is continuous. study: indicates whether the level of study of the student, which can be either \"Undergrad\", \"Grad\", \"Med Residents\" or \"Non-degree\". This variable is categorical. college: the college affiliation of the student. It can be either \"Agriculture &amp; Bioresources\", \"Arts and Science\", \"Education\", \"Nursing\", \"Kinesiology\", \"Engineering\", \"Public Health\", \"Pharmacy &amp; Nutrition\", \"Medicine\", \"Veterinary Medicine\", \"Business\", \"Law\", \"Public Policy\", \"Environment &amp; Sustainability\", \"Dentistry\", or \"Others\". This variable is categorical. origin: the origin of the student. It can be either \"Saskatchewan\", \"Out of Province\", or \"International\". This variable is categorical. distance: the distance from the rented place to school. It can be either \"less than 15 minutes\", \"15-30 minutes\", \"30-45 minutes\", or \"more than 40 minutes\". This variable is categorical. area: the area of the rented place in \\(m^2\\). This variable is continuous. washroom: whether the rented place has a private washroom. 1 indicates there is a private washroom and 0 otherwise. This variable is binary. neighborhood: neighborhood code of the rented place. This variable is categorical. course: the course that the student attend. This variable is categorical. To read the data set and save it into R working environment as an object called rentPop, use the following code rentPop &lt;- read.csv(&quot;fakeRentPop.csv&quot;) This rentPop object will be used throughout the book. "],["references.html", "References", " References Lohr, Sharon L. 2021. Sampling: Design and Analysis. Chapman; Hall/CRC. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
